{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import load_parser\n",
    "from nltk.sem import chat80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your Turn: Run the parser with maximum tracing on, i.e., cp =\n",
    "load_parser('grammars/book_grammars/sql0.fcfg', trace=3), and examine\n",
    "how the values of SEM are built up as complete edges are added\n",
    "to the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.W.c.a.l.i.C.|\n",
      "Leaf Init Rule:\n",
      "|[-] . . . . .| [0:1] 'What'\n",
      "|. [-] . . . .| [1:2] 'cities'\n",
      "|. . [-] . . .| [2:3] 'are'\n",
      "|. . . [-] . .| [3:4] 'located'\n",
      "|. . . . [-] .| [4:5] 'in'\n",
      "|. . . . . [-]| [5:6] 'China'\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[-] . . . . .| [0:1] Det[SEM='SELECT'] -> 'What' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[-> . . . . .| [0:1] NP[SEM=(?det+?n)] -> Det[SEM=?det] * N[SEM=?n] {?det: 'SELECT'}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|. [-] . . . .| [1:2] N[SEM='City FROM city_table'] -> 'cities' *\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|[---] . . . .| [0:2] NP[SEM=(SELECT, City FROM city_table)] -> Det[SEM='SELECT'] N[SEM='City FROM city_table'] *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[---> . . . .| [0:2] S[SEM=(?np+WHERE+?vp)] -> NP[SEM=?np] * VP[SEM=?vp] {?np: (SELECT, City FROM city_table)}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|. . [-] . . .| [2:3] IV[SEM=''] -> 'are' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|. . [-> . . .| [2:3] VP[SEM=(?v+?pp)] -> IV[SEM=?v] * PP[SEM=?pp] {?v: ''}\n",
      "|. . [-> . . .| [2:3] VP[SEM=(?v+?ap)] -> IV[SEM=?v] * AP[SEM=?ap] {?v: ''}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|. . . [-] . .| [3:4] A[SEM=''] -> 'located' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|. . . [-> . .| [3:4] AP[SEM=?pp] -> A[SEM=?a] * PP[SEM=?pp] {?a: ''}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|. . . . [-] .| [4:5] P[SEM=''] -> 'in' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|. . . . [-> .| [4:5] PP[SEM=(?p+?np)] -> P[SEM=?p] * NP[SEM=?np] {?p: ''}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|. . . . . [-]| [5:6] NP[SEM='Country=\"china\"'] -> 'China' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|. . . . . [->| [5:6] S[SEM=(?np+WHERE+?vp)] -> NP[SEM=?np] * VP[SEM=?vp] {?np: 'Country=\"china\"'}\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|. . . . [---]| [4:6] PP[SEM=(, Country=\"china\")] -> P[SEM=''] NP[SEM='Country=\"china\"'] *\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|. . . [-----]| [3:6] AP[SEM=(, Country=\"china\")] -> A[SEM=''] PP[SEM=(, Country=\"china\")] *\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|. . [-------]| [2:6] VP[SEM=(, , Country=\"china\")] -> IV[SEM=''] AP[SEM=(, Country=\"china\")] *\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|[===========]| [0:6] S[SEM=(SELECT, City FROM city_table, WHERE, , , Country=\"china\")] -> NP[SEM=(SELECT, City FROM city_table)] VP[SEM=(, , Country=\"china\")] *\n",
      "SELECT City FROM city_table WHERE Country=\"china\"\n"
     ]
    }
   ],
   "source": [
    "from nltk import load_parser\n",
    "cp = load_parser('grammars/book_grammars/sql0.fcfg',trace=3)\n",
    "query = 'What cities are located in China'\n",
    "trees = list(cp.parse(query.split()))\n",
    "answer = trees[0].label()['SEM']\n",
    "answer = [s for s in answer if s]\n",
    "q = ' '.join(answer)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your Turn: Extend the grammar sql0.fcfg so that it will translate (4a) into (4b), and check the values returned by the query.\n",
    "a.\t\tWhat cities are in China and have populations above 1,000,000?\n",
    "\n",
    "b.\t\tSELECT City FROM city_table WHERE Country = 'china' AND Population > 1000\n",
    "You will probably find it easiest to first extend the grammar to handle queries like What cities have populations above 1,000,000 before tackling conjunction. After you have had a go at this task, you can compare your solution to grammars/book_grammars/sql1.fcfg in the NLTK data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_10 = load_parser('file:sql0.fcfg')\n",
    "query = 'What cities have populations above 1,000,000'\n",
    "trees = list(cp.parse(query.split()))\n",
    "answer = trees[0].label()['SEM']\n",
    "answer = [s for s in answer if s]\n",
    "q = ' '.join(answer)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Translate the following sentences into propositional logic and verify that they can be processed with Expression.fromstring(). Provide a key which shows how the propositional variables in your translation correspond to expressions of English.\n",
    "\n",
    "If Angus sings, it is not the case that Bertie sulks.\n",
    "Cyril runs and barks.\n",
    "It will snow if it doesn't rain.\n",
    "It's not the case that Irene will be happy if Olive or Tofu comes.\n",
    "Pat didn't cough or sneeze.\n",
    "If you don't come if I call, I won't come if you call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ImpExpression ((P -> -Q) -> (Q -> -P))>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_expr = nltk.sem.Expression.fromstring\n",
    "read_expr('P -> Q')\n",
    "read_expr('P & Q')\n",
    "read_expr('-P -> Q')\n",
    "read_expr('-P -> Q')\n",
    "read_expr('-(P | Q)')\n",
    "read_expr('(P -> -Q) -> (Q -> -P)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bertie': 'b',\n",
      " 'boy': {('b',)},\n",
      " 'cyril': 'c',\n",
      " 'dog': {('c',)},\n",
      " 'girl': {('o',)},\n",
      " 'olive': 'o',\n",
      " 'see': {('o', 'c'), ('c', 'b'), ('b', 'o')},\n",
      " 'walk': {('c',), ('o',)}}\n"
     ]
    }
   ],
   "source": [
    "v = \"\"\"\n",
    "bertie => b\n",
    "olive => o\n",
    "cyril => c\n",
    "boy => {b}\n",
    "girl => {o}\n",
    "dog => {c}\n",
    "walk => {o, c}\n",
    "see => {(b, o), (c, b), (o, c)}\n",
    "\"\"\"\n",
    "val = nltk.Valuation.fromstring(v)\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dom = {'b', 'o', 'c'}\n",
    "g = nltk.Assignment(dom, [('x', 'o'), ('y', 'c')])\n",
    "m = nltk.Model(dom, val)\n",
    "m.evaluate('exists x.(girl(x) & walk(x))', g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b', 'o'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_expr = nltk.sem.Expression.fromstring\n",
    "fmla1 = read_expr('girl(x) | boy(x)')\n",
    "m.satisfiers(fmla1, 'x', g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b', 'c', 'o'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmla2 = read_expr('girl(x) -> walk(x)')\n",
    "m.satisfiers(fmla2, 'x', g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b', 'o'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fmla3 = read_expr('walk(x) -> girl(x)')\n",
    "m.satisfiers(fmla3, 'x', g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate('all x.(girl(x) & walk(x))', g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate('exists x.(boy(x) -> walk(x))', g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    ">>> v2 = \"\"\"\n",
    "... bruce => b\n",
    "... elspeth => e\n",
    "... julia => j\n",
    "... matthew => m\n",
    "... person => {b, e, j, m}\n",
    "... admire => {(j, b), (b, b), (m, e), (e, m)}\n",
    "... \"\"\"\n",
    ">>> val2 = nltk.Valuation.fromstring(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b', 'e', 'j', 'm'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> dom2 = val2.domain\n",
    ">>> m2 = nltk.Model(dom2, val2)\n",
    ">>> g2 = nltk.Assignment(dom2)\n",
    ">>> fmla4 = read_expr('(person(x) -> exists y.(person(y) & admire(x, y)))')\n",
    ">>> m2.satisfiers(fmla4, 'x', g2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Translate the following sentences into predicate-argument formulas of first-order logic.\n",
    "a. Angus likes Cyril and Irene hates Cyril.\n",
    "b. Tofu is taller than Bertie.\n",
    "c. Bruce loves himself and Pat does too.\n",
    "d. Cyril saw Bertie, but Angus didn’t.\n",
    "e. Cyril is a four-legged friend.\n",
    "f. Tofu and Olive are near each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'like(a, c) & hate(i,c)'\n",
    "\n",
    "'TallerThan(t, b)'\n",
    "\n",
    "'Love(b,b) & love(p,b)'\n",
    "\n",
    "'see(c,b) & -see(a,b)'\n",
    "\n",
    "'fourLegs(c)'\n",
    "\n",
    "'Near(t,o) & Near(o,t)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate the following sentences into quantified formulas of first-order logic.\n",
    "a. Angus likes someone and someone likes Julia.\n",
    "b. Angus loves a dog who loves him.\n",
    "c. Nobody smiles at Pat.\n",
    "d. Somebody coughs and sneezes.\n",
    "e. Nobody coughed or sneezed.\n",
    "f. Bruce loves somebody other than Bruce.\n",
    "g. Nobody other than Matthew loves Pat.\n",
    "h. Cyril likes everyone except for Irene.\n",
    "i. Exactly one person is asleep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'exists x.like(a,x) & exists y.like(y,j)'\n",
    "\n",
    "'exists x.(dog(x) & love(a,x) & love(x,a))'\n",
    "\n",
    "'-(exists x.smiles(x,p))'\n",
    "\n",
    "'exists x.(cough(x) & sneeze(x))'\n",
    "\n",
    "'-(exists x.(cough(x) | sneeze(x))'\n",
    "\n",
    "? 'exist x.love(b,x), b!=x'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☼ Translate the following verb phrases using λ abstracts. quantified formulas of first order logic.\n",
    "\n",
    "feed Cyril and give a capuccino to Angus\n",
    "be given 'War and Peace' by Pat\n",
    "be loved by everyone\n",
    "be loved or detested by everyone\n",
    "be loved by everyone and detested by no-one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\x.(feed(x,cyril) & give(x,cappuccino,angus))\n",
    "\\x.(give(pat,'War and Peace',x))\n",
    "all x.(\\x.love(y,x))\n",
    "all x.(\\x.love(y,x) | detest(y,x))\n",
    "all x.(\\x.love(y,x) & -detest(y,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    ">>> read_expr = nltk.sem.Expression.fromstring\n",
    ">>> e2 = read_expr('pat')\n",
    ">>> e3 = nltk.sem.ApplicationExpression(e1, e2)\n",
    ">>> print(e3.simplify())\n",
    "exists y.love(pat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly something is missing here, namely a declaration of the value of e1. In order for ApplicationExpression(e1, e2) to be β-convertible to exists y.love(pat, y), e1 must be a λ-abstract which can take pat as an argument. Your task is to construct such an abstract, bind it to e1, and satisfy yourself that the statements above are all satisfied (up to alphabetic variance). In addition, provide an informal English translation of e3.simplify().\n",
    "\n",
    "Now carry on doing this same task for the further cases of e3.simplify() shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> print(e3.simplify())\n",
    "exists y.(love(pat,y) | love(y,pat))\n",
    "\n",
    ">>> print(e3.simplify())\n",
    "exists y.(love(pat,y) | love(y,pat))\n",
    "\n",
    ">>> print(e3.simplify())\n",
    "walk(fido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
